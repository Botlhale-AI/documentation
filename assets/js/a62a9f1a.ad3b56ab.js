"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1105],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var c=o.createContext({}),u=function(e){var t=o.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=u(e.components);return o.createElement(c.Provider,{value:t},e.children)},l={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},h=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,c=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),h=u(n),d=r,m=h["".concat(c,".").concat(d)]||h[d]||l[d]||a;return n?o.createElement(m,s(s({ref:t},p),{},{components:n})):o.createElement(m,s({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,s=new Array(a);s[0]=h;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:r,s[1]=i;for(var u=2;u<a;u++)s[u]=n[u];return o.createElement.apply(null,s)}return o.createElement.apply(null,n)}h.displayName="MDXCreateElement"},2175:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return c},default:function(){return h},frontMatter:function(){return i},metadata:function(){return u},toc:function(){return p}});var o=n(7462),r=n(3366),a=(n(7294),n(3905)),s=["components"],i={},c="Speech to Text API Overview",u={unversionedId:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",id:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",isDocsHomePage:!1,title:"Speech to Text API Overview",description:"This document is a guide to the basics of using Speech to Text. This conceptual guide covers the types of requests you can make to Speech to Text, how to construct those requests, and how to handle their responses. We recommend that all users of Speech to Text read this guide before diving into the API itself.",source:"@site/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",sourceDirName:"1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton",slug:"/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",editUrl:"https://botlhale-ai.github.io/documentation/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Text to Speech",permalink:"/docs/APIs/Rest APIs/Speech APIs/TTS"},next:{title:"Speech to Text API",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/ASR"}},p=[{value:"Speech requests",id:"speech-requests",children:[]},{value:"Supported formats",id:"supported-formats",children:[]}],l={toc:p};function h(e){var t=e.components,n=(0,r.Z)(e,s);return(0,a.kt)("wrapper",(0,o.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"speech-to-text-api-overview"},"Speech to Text API Overview"),(0,a.kt)("p",null,"This document is a guide to the basics of using Speech to Text. This conceptual guide covers the types of requests you can make to Speech to Text, how to construct those requests, and how to handle their responses. We recommend that all users of Speech to Text read this guide before diving into the API itself."),(0,a.kt)("h2",{id:"speech-requests"},"Speech requests"),(0,a.kt)("p",null,"Speech-to-Text has two main methods to perform speech recognition. These are listed below:"),(0,a.kt)("h4",{id:"synchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/ASR"},"Synchronous Requests")),(0,a.kt)("p",null,"Synchronous requests (REST) sends audio data to the Speech to Text API, performs recognition on that data, and returns results after all audio has been processed. Synchronous recognition requests are limited to audio data of 1 minute or less in duration."),(0,a.kt)("h4",{id:"asynchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/long%20ASR"},"Asynchronous Requests")),(0,a.kt)("p",null,"Asynchronous Recognition (REST) sends audio data to the Speech to Text API and initiates a Long Running Operation. Using this operation, you can periodically poll for recognition results. Use asynchronous requests for audio data of any duration up to 400 minutes."),(0,a.kt)("br",null),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Content Limit"),(0,a.kt)("th",{parentName:"tr",align:null},"Audio Length"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Synchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"~ 60 seconds"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Asynchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"~ 400 minutes"))))),(0,a.kt)("h2",{id:"supported-formats"},"Supported formats"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"File Type")," - We currently only support ",(0,a.kt)("strong",{parentName:"p"},"wav, amr, flac and ogg."))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Sample Rate")," - We support all sample rates between 8000Hz and 48000 Hz. If you can choose the sample rate of the source, record the audio at 16000 Hz. This is because sample rates below that may impair the accuracy of our models and sample rates above 16000 Hz have no significant impact on the accuracy of our models."))))}h.isMDXComponent=!0}}]);