"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1105],{3905:function(e,t,n){n.d(t,{Zo:function(){return l},kt:function(){return m}});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),u=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},l=function(e){var t=u(e.components);return r.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,l=i(e,["components","mdxType","originalType","parentName"]),h=u(n),m=o,d=h["".concat(c,".").concat(m)]||h[m]||p[m]||a;return n?r.createElement(d,s(s({ref:t},l),{},{components:n})):r.createElement(d,s({ref:t},l))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,s=new Array(a);s[0]=h;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},2175:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return c},default:function(){return h},frontMatter:function(){return i},metadata:function(){return u},toc:function(){return l}});var r=n(7462),o=n(3366),a=(n(7294),n(3905)),s=["components"],i={},c="Speech to Text API",u={unversionedId:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",id:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",isDocsHomePage:!1,title:"Speech to Text API",description:"Converts speech to text using Botlhale AI's deep learning models.",source:"@site/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",sourceDirName:"1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton",slug:"/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",editUrl:"https://botlhale-ai.github.io/documentation/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Text to Speech",permalink:"/docs/APIs/Rest APIs/Speech APIs/TTS"},next:{title:"Automatic Speech Recogniton",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/ASR"}},l=[],p={toc:l};function h(e){var t=e.components,n=(0,o.Z)(e,s);return(0,a.kt)("wrapper",(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"speech-to-text-api"},"Speech to Text API"),(0,a.kt)("p",null,"Converts speech to text using Botlhale AI's deep learning models."),(0,a.kt)("br",null),(0,a.kt)("p",null,"Botlhale AI's Speech to text has two types of API requests based on audio content."),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Content Limit"),(0,a.kt)("th",{parentName:"tr",align:null},"Audio Length"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Synchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"~ 60 seconds"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Asynchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"~ 400 minutes"))))),(0,a.kt)("br",null),(0,a.kt)("h4",{id:"synchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/ASR"},"Synchronous Requests")),(0,a.kt)("p",null,"The audio file content should be approximately 1 minute to make a synchronous request. In this type of request, the user does not have to upload the data to Botlhale AI's API. This provides the flexibility to users to store the audio file in their local computer or server and reference the API to get the text."),(0,a.kt)("h4",{id:"asynchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/long%20ASR"},"Asynchronous Requests")),(0,a.kt)("p",null,"The audio file content should be approximately 400 minutes(7 hours). In this type of request, the user have to upload their data to Botlhale AI's API."))}h.isMDXComponent=!0}}]);