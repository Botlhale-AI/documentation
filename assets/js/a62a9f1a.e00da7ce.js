"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1105],{3905:function(e,t,n){n.d(t,{Zo:function(){return p},kt:function(){return d}});var r=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),u=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(c.Provider,{value:t},e.children)},l={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),h=u(n),d=o,m=h["".concat(c,".").concat(d)]||h[d]||l[d]||a;return n?r.createElement(m,s(s({ref:t},p),{},{components:n})):r.createElement(m,s({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,s=new Array(a);s[0]=h;var i={};for(var c in t)hasOwnProperty.call(t,c)&&(i[c]=t[c]);i.originalType=e,i.mdxType="string"==typeof e?e:o,s[1]=i;for(var u=2;u<a;u++)s[u]=n[u];return r.createElement.apply(null,s)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},2175:function(e,t,n){n.r(t),n.d(t,{contentTitle:function(){return c},default:function(){return h},frontMatter:function(){return i},metadata:function(){return u},toc:function(){return p}});var r=n(7462),o=n(3366),a=(n(7294),n(3905)),s=["components"],i={},c="Speech-to-Text API Overview",u={unversionedId:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",id:"APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",isDocsHomePage:!1,title:"Speech-to-Text API Overview",description:"This page outlines the fundamentals of using the Speech-to-Text API. Covered in this page is information on the types of requests you can make using Speech-to-Text, how to construct those requests, and how to handle their responses. It's recommended that you read this page in its entirety before diving into the Speech API.",source:"@site/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",sourceDirName:"1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton",slug:"/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/Overview",editUrl:"https://botlhale-ai.github.io/documentation/docs/1 - APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/0 - Overview.md",tags:[],version:"current",sidebarPosition:0,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Text-to-Speech API",permalink:"/docs/APIs/Rest APIs/Speech APIs/TTS"},next:{title:"Speech to Text API",permalink:"/docs/APIs/Rest APIs/Speech APIs/Automatic Speech Recogniton/ASR"}},p=[{value:"Speech requests",id:"speech-requests",children:[]},{value:"Supported formats",id:"supported-formats",children:[]}],l={toc:p};function h(e){var t=e.components,n=(0,o.Z)(e,s);return(0,a.kt)("wrapper",(0,r.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"speech-to-text-api-overview"},"Speech-to-Text API Overview"),(0,a.kt)("p",null,"This page outlines the fundamentals of using the Speech-to-Text API. Covered in this page is information on the types of requests you can make using Speech-to-Text, how to construct those requests, and how to handle their responses. It's recommended that you read this page in its entirety before diving into the Speech API."),(0,a.kt)("h2",{id:"speech-requests"},"Speech requests"),(0,a.kt)("p",null,"Speech-to-Text has two main methods of performing speech recognition. These are listed and described as follows:"),(0,a.kt)("h4",{id:"synchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/ASR"},"Synchronous Requests")),(0,a.kt)("p",null,"With synchronous requests (REST), audio data is sent to the Speech-to-Text API, recognition is performed on that data, and results are returned once all audio has been processed. Synchronous recognition requests are limited to audio data of 1 minute or less in duration."),(0,a.kt)("h4",{id:"asynchronous-requests"},(0,a.kt)("a",{parentName:"h4",href:"/docs/APIs/Rest%20APIs/Speech%20APIs/Automatic%20Speech%20Recogniton/long%20ASR"},"Asynchronous Requests")),(0,a.kt)("p",null,"With asynchronous requests (REST), audio data is sent to the Speech-to-Text API and a Long Running Operation is initiated. Using this operation, you can periodically poll for recognition results. Asynchronous requests can be used for audio data with a duration up to 400 minutes."),(0,a.kt)("br",null),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Request Type"),(0,a.kt)("th",{parentName:"tr",align:null},"Audio Length Limit"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Synchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"\u2264 60 seconds"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Asynchronous Request"),(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"\u2264 400 minutes"))))),(0,a.kt)("h2",{id:"supported-formats"},"Supported formats"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"File Type")," - We currently only support ",(0,a.kt)("strong",{parentName:"p"},"wav, amr, flac, and ogg.")," audio files.")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},(0,a.kt)("inlineCode",{parentName:"p"},"Sample Rate")," - We support all sample rates between 8 000 Hz and 48 000 Hz. If you can choose the sample rate of the source, record the audio at 16 000 Hz. This is because sample rates below that might affect the accuracy of our models, and sample rates above 16 000 Hz have no significant impact on the accuracy of our models."))))}h.isMDXComponent=!0}}]);